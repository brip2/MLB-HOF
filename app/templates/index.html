<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
        <meta name="description" content="" />
        <meta name="author" content="" />
        <title>Agency - Start Bootstrap Theme</title>
        <!-- Favicon-->
        <link rel="icon" type="image/x-icon" href="assets/favicon.ico" />
        <!-- Font Awesome icons (free version)-->
        <script src="https://use.fontawesome.com/releases/v6.1.0/js/all.js" crossorigin="anonymous"></script>
        <!-- Google fonts-->
        <link href="https://fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css" />
        <link href="https://fonts.googleapis.com/css?family=Roboto+Slab:400,100,300,700" rel="stylesheet" type="text/css" />
        <!-- Core theme CSS (includes Bootstrap)-->
        <link href="{{url_for('static', filename= 'css/styles.css')}}" rel="stylesheet" />
    </head>
    <body id="page-top">
        <!-- Navigation-->
        <nav class="navbar navbar-expand-lg navbar-dark bg-dark fixed-top" id="mainNav">
            <div class="container">
                <a class="navbar-brand" href="#page-top"><img src="assets/img/navbar-logo.svg" alt="..." /></a>
                <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
                    Menu
                    <i class="fas fa-bars ms-1"></i>
                </button>
                <div class="collapse navbar-collapse" id="navbarResponsive">
                    <ul class="navbar-nav text-uppercase ms-auto py-4 py-lg-0">
                        <li class="nav-item"><a class="nav-link" href="#about">About</a></li>
                        <li class="nav-item"><a class="nav-link" href="#exploration">Exploration</a></li>
                        <li class="nav-item"><a class="nav-link" href="#ml">Machine Learning</a></li>
                        <li class="nav-item"><a class="nav-link" href="#conclusion">Conclusion</a></li>
                    </ul>
                </div>
            </div>
        </nav>
        <!-- Masthead-->
        <header class="masthead">
            <div class="container">
                <div class="masthead-heading text-uppercase">Predicting MLB Hall of Famers</div>
                <a class="btn btn-primary btn-xl text-uppercase" href="#about">Explore Data!</a>
            </div>
        </header>
        <!-- About section-->
        <section id="about">
            <div class="container px-4">
                <div class="row gx-4 justify-content-center">
                    <div class="col-lg-8">
                        <h2>Objective
                        </h2>
                        <p class="lead">This project makes use of Lahman's Baseball Database which contains both batting and pitching statistics dating back to 1871 (and much more). In this project, I only attempt to predict whether a given position player will be inducted into the Hall of Fame based on the aggregate statistics across their career in the MLB. <br><br> Data from multiple data sets will be pooled such that only what I believe to be the most important statistics in determining a Hall of Fame player will be used in the models.  </p>
                    </div>
                </div>
            </div>
        </section>
        <!-- Exploration section-->
        <section class="bg-light" id="exploration">
            <div class="container px-4">
                <div class="row gx-4 justify-content-center">
                    <div class="col-lg-8">
                    <h1 id="top-level-heading">Exploration</h1><br/>
                    </div>
                    <div class="col-lg-8">
                        <h3>Correlation of the Variables</h3>
                        <p class="lead">We can see that there is high positive correlation in the upper left corner of the heatmap. All of these are statistics that increase the longer a player has been in the league. The last row or the last column shows the correlation with the target class, "hof." I will be trying to predict this from the other statistics. Whether a player bats left, right handed or both does not appear very correlated with the target class. These variables could be dropped before inputting the data to the models, though they were a late addition in an attempt to improve accuracy after initial runs with purely hitting statistics. The models seen later were run with data that includes the batting side and throwing arm of the player, as well as their most frequent position (not shown in this correlation heat map).  </p>
                    <iframe width="850" height="550" title="Correlation Table of Features" src="{{url_for('static', filename='corr_heatmap.html')}}")></iframe> <br>
                    </div>
                    <div class="col-lg-8">
                        <h3>Hall of Famers by Position</h3>
                        <p class="lead">Exploring the data, I found that the batting data includes hitting statistics for pitchers. Because I am only attempting to classify position players, I will drop pitchers from the data set. We cannot predict a pitcher being inducted to the hall of fame through batting statistics. To predict on pitchers, we would need a separate model trained on pitching statistics. From this plot, there also seems to be an imbalance in hall of famers by position, so we will include this data when training the models. </p>
                        <iframe width="700" height="600" title="Class Counts" src="{{url_for('static', filename='hof_by_pos.html')}}"></iframe> <br><br>
                    </div>
                    <div class="col-lg-8">
                        <h3>Hall of Famers by Years Played</h3>
                        <p class="lead">At this point, it is important to note that I have already gone through the data to determine player eligibility. To be eligible to be voted into the Hall of Fame, a player needs ten years of MLB service. They also must have been retired from the league for five years. All ineligible players have been dropped. <br><br> Separately, we see that the majority of Hall of Famers played well more than ten years. We can see from the pie chart, going counter-clockwise that the wedges increase in size with the number of years played. They become smaller again for the few players who had very long careers (24+ seasons). </p>
                        <iframe width="500" height="550" title="HOFer Years Played" src="{{url_for('static', filename= 'hof_pie_years.html')}}"></iframe>  
                        <br>     
                    </div>
                    <div class="col-lg-8">
                        <h3>Non Hall of Famers by Years Played</h3>
                        <p class="lead">On par with the previous plot, those who were eligible and did not get inducted to the Hall of Fame were more likely to have careers closer to ten years.</p>
                    <iframe width="500" height="550" title="Non-HOFer Years Played" src="{{url_for('static', filename= 'not_hof_pie_years.html')}}"></iframe> <br>
                    </div>
                    <div class="col-lg-8">
                        <h3>Hits and At-Bats Correlation</h3>
                        <p class="lead">We see there is a very high correlation between hits and at Bats, I will be computing the batting average of the players and dropping the at-bats variable. Batting average is a much more important statistic in determining a HOFer than number of at bats. <br><br> As an aside, we can see the hall of famers emerging with more hits and at bats. We can see several outliers who statistically seem that they should be hall of famers. One, with the most hits and at bats, is Pete Rose, whose use of steroids lost him many votes. Another is Derek Jeter, who was in fact inducted to the hall of fame in 2020. When looking back at the Hall of Fame data frame, I noticed it was not updated for the 2020 inductees. Visualizing the data is very effective in realizing missing data, and finding peculiarities. <br><br> This plot also made me realize that pitchers were included in the batting statistics and needed to be dropped. We see that there are players with very few hits and at-bats that are labeled as hall of famers. Including these data points in our training data would be very confusing for our models. <br><br> See if you can find your favorite player by hovering over the data! </p>
                        <iframe width="1020" height="620" title="{{url_for('static', filename= 'H_AB_scatter.html')}}"></iframe> <br><br>
                    </div>
                    <div class="col-lg-8">
                        <h3>Hits and Batting Average Correlation</h3>
                        <p class="lead">We see a similar trend as with Hits/AB correlation. We see the pitchers are outliers with low averages, labeled as HOFers. </p>
                        <iframe width="1020" height="620" title="{{url_for('static', filename= 'H_AVG_scatter.html')}}"></iframe> <br><br>
                    </div>
                    <div class="col-lg-8">
                        <h3>Class Imbalance</h3>
                        <p class="lead">We have a high class imbalance, as only 162 of the 2262 players included in our final data set are Hall of Famers. We will need to consider this when deciding on a metric to assess our models.</p>
                        <iframe width="400" height="400" title="{{url_for('static', filename= 'hof_counts.html')}}"></iframe>
                        <iframe width="400" height="400" title="HOF Pie" src="{{url_for('static', filename= 'hof_pie.html')}}"></iframe>
                        <br>
                </div>
            </div>
        </section>
        <!-- ML section-->
        <section id="ml">
            <div class="container px-4">
                <div class="row gx-4 justify-content-center">
                    <div class="col-lg-8">
                        <h1>Machine Learning</h1></br>
                        <p class="lead"> For each of the first three machine learning models, I run a Grid Search on a range of important parameters. First, optimizing for the accuracy score and then for the recall score. Accuracy is not a good metric to rate our models because of the high class imbalance. Of the 2262 players in the final data set, only 162 are hall of famers. It would be wrong to use accuracy as a metric here, because if we were to classify all players as non-hall of famers, we would achieve an accuracy of 92.8%. Which is not bad, but not at all helpful. Instead, we should be using recall as our metric. <br><br></p>

                        <div class="qtn">
                            <div class="frac">
                              <div class="numer">true positives</div>
                              <div class="denom">true positives + false negatives</div>
                              <br>
                            </div>
                        </div>

                        <p class="lead"><br><br> I will be comparing the misclassification of our target class when using Grid Search to optimize parameters for accuracy and for recall. The results will be visualized in proportion heat maps produced from a confusion matrix, where the columns are divided by the number of instances of each class. Along left-right diagonal is the recall for Non-Hall of Famers and Hall of Famers.</p>
                        
                    </div>
                    <div class="col-lg-8">
                        <h2>Logistic Regression: Explanation</h2>
                        <p class="lead">First, I try logistic regression because our classification is binary. Logistic regression begins with a best-fit line as in linear regression. Then, a sigmoid function squeezes the predicted value between 0 and 1, indicating a probability. If this value is above our threshold, it will be classified as one class, otherwise it will be classified as the other. </p>
                        <img src="{{url_for('static', filename= 'images/lr_img.png')}}" class="page-image" />
                    </div>

                    <div class="col-lg-8">
                        <h2>Logistic Regression: Results</h2>
                        <h3>Accuracy</h3>
                        <iframe width="800" height="400" title="Logistic Regression Accuracy Confusion Matrix" src="{{url_for('static', filename= 'lr_acc.html')}}"></iframe>
                        <p class="lead">Accuracy of 95.4% and 46.8% recall on the training data. </p>
                        <h3>Recall</h3>
                        <iframe width="800" height="400" title="Logistic Regression Recall Confusion Matrix" src="{{url_for('static', filename= 'lr_recall.html')}}"></iframe>
                        <p class="lead">When optimizing for recall, the grids earch has found parameters that bring recall all the way to 89.4%. But when we call at the other entries of the heat map, we see something weird. The threshold was set in such a way that the model is too likely to predict a given player to be a Hall of Famer. Over 3x the number of Hall of Famers in the data were predicted to be Hall of Famers. Now, we are getting way too many false positives.</p>
                    </div>
                    <div class="col-lg-8">
                        <h2>K Nearest Neighbors: Explanation</h2>
                        <p class="lead">K Nearest Neighbors looks at the k closest data points in the high dimensional space of our variables. It takes a majority vote of the class labels of those k points to classify an unseen data point.</p>
                        <img src="{{url_for('static', filename= 'images/knn_img.png')}}" class="page-image" width="500"/>
                    </div>
                    <div class="col-lg-8">
                        <h2>K Nearest Neighbors: Results</h2>
                        <h3>Accuracy</h3>
                        <iframe width="800" height="400" title="KNN Accuracy Confusion Matrix" src="{{url_for('static', filename= 'knn_acc.html')}}"></iframe>
                        <p class="lead">Accuracy of 94.1% and 23.4% recall on the training data.</p>
                        <h3>Recall</h3>
                        <p class="lead">Here we have a confusion matrix with the results of the linear regression applied on our testing data set. A confusion matrix for a classification problem tells us the number of correct and incorrect predictions for every class (for example wealthy). For example, the model may have classified 10 countries with average GDP as average and classified 2 countries with average GDP incorrectly, shown in the below confusion matrix. Linear regression performed exceptionally well on countries with average GDP.</p>
                        <iframe width="800" height="400" title="KNN Recall Confusion Matrix" src="{{url_for('static', filename= 'knn_recall.html')}}"></iframe>
                        <p class="lead"> Our recall is now 34.0%. We achieved over a 10% improvement using a grid search to optimize recall, but the score still not very good.</p>
                    </div>
                    <div class="col-lg-8">
                        <h2>Support Vector Machine: Explanation</h2>
                        <p class="lead">SVM creates a hyperplane in the high-dimensional space of features. The support vectors are the nearest data points on either side of the plane. SVM attempts to maximize the space between the hyperplane and the support vectors. That distance is called the margin. </p>
                        <img src="{{url_for('static', filename= 'images/svm_img.png')}}" class="page-image" width="500"/>
                    </div>
                    <div class="col-lg-8">
                        <h2>Support Vector Machine: Results</h2>
                        <h3>Accuracy</h3>
                        <iframe width="800" height="400" title="SVM Accuracy Confusion Matrix" src="{{url_for('static', filename= 'svm_acc.html')}}"></iframe>
                        <p class="lead">Accuracy of 95.6% and 42.6% recall on the training data</p>
                        <h3>Recall</h3>
                        <iframe width="800" height="400" title="SVM Recall Confusion Matrix" src="{{url_for('static', filename= 'svm_recall.html')}}"></iframe>
                        <p class="lead">Our recall slightly improves to 44.7%. </p>
                    </div>
                    <div class="col-lg-8">
                        <h2>Neural Networks: Explanation</h2>
                        <p class="lead">Because of the complexity of the problem, a neural network may be the best solution. There are so many variables in the input data, and no clear definition of what makes a player a hall of famer. A neural network works through a series of layers from the input layer to the output. Each layer has a set of nodes with weights and biases to transform the input from the previous layer. It learns through backpropagation, going from its prediction back to the input layer, adjusting weights and biases for each training example. <br><br> I added a very simple neural network as an afterthought and there is much room for improvement.</p>
                        <img src="{{url_for('static', filename= 'images/nn_img.png')}}" class="page-image" width="500"/>
                    </div>

                    <div class="col-lg-8">
                        <h2>Neutral Networks: Results</h2>
                        <h3>Accuracy</h3>
                        <iframe width="800" height="400" title="Neural Network Confusion Matrix" src="{{url_for('static', filename= 'nn_acc.html')}}"></iframe>
                        <p class="lead">We get a recall of 44.7%, the same as for SVM when optimizing parameters for recall. This is not bad considering how little time was spent developing the neural network, only two layers. There is certainly room for improvement here.</p>
                    </div>
                </div>
            </div>
        </section>
        <!-- Conclusions -->
        </section>
        <section class="bg-light" id="conclusion">
            <div class="container px-4">
                <div class="row gx-4 justify-content-center">
                    <div class="col-lg-8">
                    <h1 id="top-level-heading">Conclusion</h1><br/>
                    </div>
                    <div class="col-lg-8">

                        <p class="lead"> We see that all of our models perform decently well when using accuracy as the metric. However, we saw that accuracy may not the best metric to use when we have such a high class imbalance. Optimizing for recall is the better choice here because we have so few Hall of Famers. Recall was improved for the three main models when the grid search used it to score instead of accuracy. However, the best recall was still only 44.6%, achieved by both SVM and the Neural Network. <br><br> This project has plenty of room for improvement. There likely needs to be a better choice of features to improve scoring. Data from other data sets on Lahman's database could prove useful. For instance, this analysis neglected all postseason stats and All Star selections. These two features could be much more deterministic of a Hall of Fame player than other features that were included. Our models may have also been thrown off by players such as Pete Rose and Barry Bonds who are clear shoo-in Hall of Famers by their statistics. However, their use of steroids cost them induction into the Hall. Another possible feature to include would be use of steroids, so the models can discern why these two players were not inducted. <br><br> Regardless, this project showcases the importance of choosing a proper metric during model selection. It also demonstrates how much can be learned from data visualization, including insight that may not be possible through querying. We also see the great importance of feature selection. Similar results could likely be achieved through only several factors, such as batting average, home runs, postseason games, world series titles and all star appearances. So much to learn from, and space for improvement or extension on this project! </p>

                    </div>
                </div>
            </div>
        </section>
        <!-- Footer-->
        <footer class="footer py-4">
            <div class="container">
                <div class="row align-items-center">
                    <div class="col-lg-4 text-lg-start">Copyright &copy; Brian Ripley</div>
                </div>
            </div>
        </footer>
       
        <!-- Bootstrap core JS-->
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>
        <!-- Core theme JS-->
        <script src="js/scripts.js"></script>
        <!-- * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *-->
        <!-- * *                               SB Forms JS                               * *-->
        <!-- * * Activate your form at https://startbootstrap.com/solution/contact-forms * *-->
        <!-- * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *-->
        <script src="https://cdn.startbootstrap.com/sb-forms-latest.js"></script>
    </body>
</html>
